###Chap. 0 Introduction 导引###

本书简单总结了硬件和软件并行知识，着重介绍如何利用 C 语言的 MPI，pthreads 和 OpenMP 并行接口开发高效并行程序。其中 MPI 貌似是分布式内存编程，pthreads 和 OpenMP 主要是共享内存编程，OpenMP是对 C 语言更高层次的扩展， pthreads 提供了一些 OpenMP 不可用的协调操作。

嗯...“CS 有过多的必修课要求”。

三套 API 的章节是相互独立的，但是没有基础的人应该先读 Chap. 1。Chap. 6 开发了两个复杂并行系统：并行 n 体程序求解，并行树搜索。本书有一套 slides。

为什么需要并行计算

* 社会主义初级阶段的基本矛盾，性能永远不够用。

* 单核的性能难以继续提升，处理器的发展转向多核并行。

* 很难把串行程序自动转换为并行程序。很多时候并行也不是通过把串行程序各个步骤并行化实现的，而是回溯并发现新的算法获得的。

    示例：计算 n 个数并累加，串行实现：循环计算，边计算边累加。并行实现：每个核计算部分值求部分和（存储在自己的私有变量中），并将结果发送至 master 核中。为实现 master 核，需要用一个条件判断语句（类似 fork 后的结构）。
    
    计算单元到了一定规模时，可以用分治的方法进行 merge。第一种算法是串行的思想，第二种就比较并行化了。
    
怎样编写并行程序

基本思想：把任务分配给多个单元，两种方法：任务并行和数据并行。最大的问题：计算单元之间的通信与协调，同步。单元之间应该负载平衡。最强大的并行程序具有显式的并行结构。编写并行程序比串行程序更加复杂，并且非常复杂。

栗子：同步点：在各个单元执行的任务中加入一个同步点函数，作用是阻塞，直至所有单元都进入该函数。

并行、并发与分布式

并发计算中多个任务可以同时执行，并行计算中程序的多个任务之间紧密协作，分布式计算中一个程序与其他程序协作。

并行计算的单元之间练习更紧密，分布式则耦合更松。本书主要关注并行。